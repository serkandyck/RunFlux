{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOhtH9IY70KpTwNM7lk/HUH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KN72eHvyPzi4","executionInfo":{"status":"ok","timestamp":1724339691325,"user_tz":-120,"elapsed":4379,"user":{"displayName":"Gerald Stampfel","userId":"16044924958378286623"}},"outputId":"74e6736b-c924-4c61-c9e2-f104cb442bda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Pod started: https://www.runpod.io/console/pods\n"]}],"source":["# @title # RunFlux\n","\n","# @markdown ## Train a FLUX1-dev LoRA on RunPod.\n","\n","# @markdown * 📸 **Caption 10-15 images**, upload to Google Drive or Dropbox\n","\n","# @markdown * ☁️ **Choose a GPU** on RunPod\n","\n","# @markdown * 🤗 Choose a **Hugging Face target repo**\n","\n","# @markdown * 🔑 **Insert API tokens** for Hugging Face and RunPod\n","\n","# @markdown * 🔑 Accept the FLUX1-dev licence: https://huggingface.co/black-forest-labs/FLUX.1-dev\n","\n","# @markdown * 🪄 **Click RUN to start your Pod**. LoRA adapters and sample images will be uploaded to your HF repo while training. The pod will shut down when training is complete.\n","\n","# @markdown 💪💪💪 *This notebook trains with the `ai-toolkit` created by Ostris. Make sure to give him a star and follow*:\n","# @markdown * https://github.com/ostris/ai-toolkit\n","# @markdown * https://x.com/ostrisai\n","\n","# @markdown ---\n","\n","# @markdown ## 📸 Images and captions\n","IMAGE_ARCHIVE = \"\" # @param {type:\"string\"}\n","\n","# @markdown * Ideally use a **Google Drive** or **Dropbox** share link, it will be converted to a direct download link. If it's not a Google/Dropbox URL, make sure it is a **direct download link**.\n","\n","# @markdown * The archive has to be a `.zip` containing image and text files:\n","# @markdown * For example: `DSCN1744.JPG` and `DSCN1744.txt`\n","# @markdown * The `.txt` file contains the caption of each image. For example: \"`p3r5on with red hair, playing chess at the park, bomb going off in the background`\"\n","# @markdown * 10-15 images are enough\n","\n","TRIGGER_WORD = \"p3r5on\" # @param {type:\"string\"}\n","\n","\n","# @markdown ---\n","\n","# @markdown ## 💪 Training Parameters\n","# @markdown Leave the defaults for a first try.\n","\n","LORA_RANK = 16 # @param {type:\"integer\"}\n","LORA_ALPHA = 16 # @param {type:\"integer\"}\n","BATCH_SIZE = 1 # @param {type:\"integer\"}\n","SAMPLE_STEPS = 500 # @param {type:\"integer\"}\n","SAVE_STEPS = 500 # @param {type:\"integer\"}\n","TRAIN_STEPS = 3000 # @param {type:\"integer\"}\n","LEARNING_RATE = 0.0001 # @param {type:\"number\"}\n","QUANTIZE_MODEL = True # @param {type:\"boolean\"}\n","SEED = 42 # @param {type:\"integer\"}\n","\n","\n","# @markdown ---\n","\n","# @markdown ## 🤗 Output\n","# @markdown This HF repo will be created and the LoRA adapters uploaded once training is finished.\n","\n","HF_REPO = \"user/repo\" # @param {type:\"string\"}\n","\n","# @markdown ---\n","\n","# @markdown ## ☁️ Cloud GPU\n","\n","# @markdown Choose a GPU with at least 24 GB VRAM, check https://www.runpod.io/pricing\n","\n","GPU = \"NVIDIA GeForce RTX 4090\" # @param [\"NVIDIA A100 80GB PCIe\", \"NVIDIA A100-SXM4-80GB\", \"NVIDIA A30\", \"NVIDIA A40\", \"NVIDIA GeForce RTX 3090\", \"NVIDIA GeForce RTX 3090 Ti\", \"NVIDIA GeForce RTX 4090\", \"NVIDIA H100 80GB HBM3\", \"NVIDIA H100 NVL\", \"NVIDIA H100 PCIe\", \"NVIDIA L4\", \"NVIDIA L40\", \"NVIDIA L40S\", \"NVIDIA RTX 5000 Ada Generation\", \"NVIDIA RTX 6000 Ada Generation\", \"NVIDIA RTX A5000\", \"NVIDIA RTX A6000\", \"Tesla V100-SXM2-32GB\"]\n","CLOUD_TYPE = \"SECURE\" # @param [\"COMMUNITY\", \"SECURE\"]\n","POD_NAME = \"FLUX1-DEV Train LoRa\" # @param {type:\"string\"}\n","\n","# @markdown ---\n","\n","# @markdown ## 🔑 Tokens\n","# @markdown Create Runopd and Hugging Face tokens and insert here.\n","\n","# @markdown * https://www.runpod.io/console/user/settings (**Read & Write** token)\n","\n","# @markdown * https://huggingface.co/settings/tokens  (**Write** token)\n","\n","RUNPOD_TOKEN = \"\" # @param {type:\"string\"}\n","HF_TOKEN = \"\" # @param {type:\"string\"}\n","\n","# @markdown ---\n","\n","# @markdown ## 🚨 Before you start\n","\n","# @markdown Sign into HuggingFace and accept the FLUX1-dev access: https://huggingface.co/black-forest-labs/FLUX.1-dev\n","\n","\n","!pip install -qqq runpod --progress-bar off\n","import runpod, re\n","\n","runpod.api_key = RUNPOD_TOKEN\n","HUGGINGFACE_TOKEN = HF_TOKEN\n","\n","def to_direct_link(url):\n","  def extract(url, pattern):\n","      match = re.search(pattern, url)\n","      return match.group(1) if match else None\n","\n","  if \"drive.google.com\" in url:\n","    if \"id=\" in url:\n","      fileId = extract(url, r'id=([a-zA-Z0-9_-]+)')\n","    else:\n","      fileId = extract(url, r'/d/([a-zA-Z0-9_-]+)')\n","    return f'https://drive.google.com/uc?export=download&id={fileId}' if fileId else None\n","  elif \"dropbox.com\" in url:\n","    return url.replace(\"dl=0\", \"dl=1\")\n","  else:\n","    return url\n","\n","IMAGE_ARCHIVE_DIRECTLINK = to_direct_link(IMAGE_ARCHIVE)\n","\n","assert IMAGE_ARCHIVE_DIRECTLINK is not None, \"Can't parse URL\"\n","assert len(RUNPOD_TOKEN) > 0\n","assert len(HF_TOKEN) > 0\n","assert len(HF_REPO) > 0\n","\n","pod = runpod.create_pod(\n","    name=POD_NAME,\n","    image_name=\"runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04\",\n","    gpu_type_id=GPU,\n","    cloud_type=CLOUD_TYPE,\n","    gpu_count=1,\n","    container_disk_in_gb=50,\n","    volume_in_gb=10,\n","    docker_args=f'bash -c \\'cd /workspace; git clone https://github.com/geronimi73/RunFlux; bash /workspace/RunFlux/runpod.sh\\'',\n","    volume_mount_path=\"/workspace\",\n","    env={\n","        \"HF_REPO\": HF_REPO,\n","        \"HUGGINGFACE_TOKEN\": HF_TOKEN,\n","        \"IMAGE_ARCHIVE\": IMAGE_ARCHIVE_DIRECTLINK,\n","        \"TRIGGER_WORD\": TRIGGER_WORD,\n","        \"LORA_RANK\": LORA_RANK,\n","        \"LORA_ALPHA\": LORA_ALPHA,\n","        \"BATCH_SIZE\": BATCH_SIZE,\n","        \"SAMPLE_STEPS\": SAMPLE_STEPS,\n","        \"SAVE_STEPS\": SAVE_STEPS,\n","        \"STEPS\": TRAIN_STEPS,\n","        \"LEARNING_RATE\": LEARNING_RATE,\n","        \"QUANTIZE_MODEL\": QUANTIZE_MODEL,\n","        \"SEED\": SEED,\n","    }\n",")\n","\n","\n","print(\"Pod started: https://www.runpod.io/console/pods\")\n"]}]}